---
permalink: /
excerpt: ""
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am currently an AP at the [School of Computer Science and Artificial Intelligence, Zhengzhou University](https://www7.zzu.edu.cn/csai/). I received my Ph.D. from the Natural Language Processing Laboratory at [Soochow University](https://www.suda.edu.cn/), supervised by [Junhui Li](https://web.suda.edu.cn/jhli/) and [Min Zhang](https://zhangminsuda.github.io/). During my doctoral studies, I conducted research internships at Huawei 2012 Lab and the Advanced Translation Technology (ATT) Research Group at the National Institute of Communications Technology (NICT), Japan. After completing my Ph.D., I joined the Huawei 2012 Lab. My research interests include machine translation, with a particular focus on enhancing long-text and document-level translation.

### üîà JOIN US!
Inspired by the philosophy that understanding emerges through creation, my research aims to advance the foundations and applications of large language models. I am particularly interested in exploring how foundation models can be designed, adapted, and evaluated to better support complex reasoning and long-context generation. My work seeks to bridge model capabilities with practical generation and evaluation challenges in real-world, document-level scenarios.

**Do not hesitate to drop me an email for any possible collaboration if you are interested in these directions:**

- **Foundation Models**: large-scale pretraining, architectural design, and capability analysis
- **Long-Context Generation and Evaluation**: document-level and long-text generation, coherence modeling, and automatic evaluation
- **Multimodal Foundation Models**: unified modeling across text, speech, and vision, and cross-modal understanding and generation


### üî• News
- 2025.12: Our paper "__A Unified Framework for Document-level Repair and Translation with Global Awareness__" is accepted by [TASLP](https://signalprocessingsociety.org/publications-resources/ieee-transactions-audio-speech-and-language-processing)
- 2025.12: Our paper "__Enhancing LLM-based Context-Aware Machine Translation via Multi-phase and Multi-task Prompt Tuning__" is accepted by [TNNLS](https://cis.ieee.org/publications/t-neural-networks-and-learning-systems)

### üë®‚Äçüéì Education
- 2020.09-2024.09, PhD in NLP Lab at [Soochow University](https://www.suda.edu.cn/), supervised by [Junhui Li](https://web.suda.edu.cn/jhli/) and [Min Zhang](https://zhangminsuda.github.io/)
- 2018.09-2020.06, M.S in NLP Lab at [Soochow University](https://www.suda.edu.cn/), supervised by [Fang Kong](https://scst.suda.edu.cn/11/55/c30767a528725/page.htm)
- 2014.09-2018.06, B.E at [Henan University](https://www.henu.edu.cn/)

### üíª Work Experience
- 2021.10-2022.10, Research Intern, Advanced Translation Technology (ATT) Research Group at the National Institute of Communications Technology (NICT)
- 2023.09-2024.09, Research Intern, Translation Service Center (TSC) at Huawei 2012 Lab
- 2024.10-2025.10, Researcher, Translation Service Center (TSC) at Huawei 2012 Lab
- 2025.12-Now, Assistant Professor, Zhengzhou University

### üìù Selected Publications
- Encouraging Lexical Translation Consistency for Document-Level Neural Machine Translation. [[Paper]()]<br>
**Xinglin Lyu**, Junhui Li, Zhengxian Gong, Min Zhang. 2021. EMNLP. 
- Modeling Consistency Preference via Lexical Chains for Document-level Neural Machine Translation. [[Paper]()]<br>
**Xinglin Lyu**, Junhui Li, Shimin Tao, Hao Yang, Min Zhang. 2022. EMNLP. 
- DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators. [[Paper]()][[Code]()]<br>
**Xinglin Lyu**, Junhui Li, Yanqing Zhao, Min Zhang, Daimeng Wei, Shimin Tao, Hao Yang, Min Zhang. 2024. EMNLP. 
- Refining History for Future-Aware Neural Machine Translation.[[Paper]()]<br>
**Xinglin Lyu**, Junhui Li, Min Zhang, Chenchen Ding, Hideki Tanaka, Masao Utiyama. 2022. TASLP.
- A Survey of Document-level Neural Machine Translation. [[Paper]()]<br>
**Xinglin Lyu**, Junhui Li, Shimin Tao, Hao Yang, Min Zhang. 2024. Journal of Software.
- DoCIA: An Online Document-Level Context Incorporation Agent for Speech Translation. [[Paper]()][[Code]()]<br>
**Xinglin Lyu**, Junhui Li, DaiMeng Wei, Min Zhang, Shimin Tao, Hao Yang, Min Zhang. 2025. ACL findings.

